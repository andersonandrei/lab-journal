-# -- mode: org --
# -- coding: utf-8 --
#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:  Andrei's Journal
#+AUTHOR:      Andrei
#+LANGUAGE:    en
#+TAGS: noexport(n) Stats(S)
#+TAGS: Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) Paper(p) Presentation(p) Scheduler(S) Denis(D) Clément(C) Andrei(a) Qarnot(q) WeekReview(w) CodeReviewed(c)
#+TAGS: DataVis(v) PaperReview(W)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!) | REPORT(r!)

* Week 06-12 / 13-02
** wednesday, 06-02-2019
:LOGBOOK:  
- State "TODO"       from ""           [2019-03-13 qua 15:16]
:END:      
*** 18:02 Meeting, org-journal                                    :OrgMode:
**** Starting on org-journal
***** Trying o do something in the org-jornal1. 
****** Creating a list
     1. Hello
     2. Hi
     3. Salut
	1. Ça vá?
     4. Learning how to do some lists
     5. Creating a lot of topics

**** Todays meeting:
***** Specified each part in the project.
***** Actually, we have two main layers to keep attention: scheduler and allocation.
***** My work will be on the allocation: *DO THE FIRST VERSION OF THE SCHEDULER*:
****** For this, I will use some data from:
******* The INPUT (jobs)
******** Priority
******** Client
******** etc
******* The QBoxes (status from each QBOX):
******** Local data
******** Status(how full it is)

**** DONE LIST
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:16]
:END:      
***** DONE Learn BatSim
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-07 qui 14:29]
- State "TODO"       from "WAITING"    [2019-02-07 qui 14:29]
- State "WAITING"    from "TODO"       [2019-02-07 qui 14:28] \\
  Waiting ...
****** WAITIGN Read about it
:END:      
*:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-07 qui 14:36] \\
  GBOOK:  
- State "DONE"       from "TODO"       [2019-02-11 seg 17:35]
:END:      
:END:
****** DONE First examples
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-11 seg 17:* TODO Install
***** DONE Read two papers
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-13 qua 18:16]
- State "WAITING"    from "DONE"       [2019-02-11 seg 17:35]
- State "DONE"       from "TODO"       [2019-02-11 seg 17:35]
:END:      
****** DONE How future buildings...
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:16]
:END:      
****** DONE Heating as a cloud...
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:16]
:END:      

** thursday, 07-02-2019...
*** Journal

**** Some tips with Pedro

***** Headers

***** Tags

***** etc

*** Research

**** BATSIM

***** DONE First examples on BATSIM website
:LOGBOOK:  
- State "DONE"       from ""           [2019-02-08 sex 18:00]
- State "WAITING"    from "TODO"       [2019-02-07 qui 17:52] \\
  The installation is not working
:END:      

***** DONE First example on GitLab Prototype repo
DEADLINE: <2019-02-08 sex>
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-11 seg 17:33]
- State "WAITING"    from "TODO"       [2019-02-07 qui 17:52] \\
  The installation of BATSIM is not working
:
** friday, 08-02-2019
*** Batsim
**** I installed it and performed the first example that includes: exectution and statistics.
**** If I understood well the structure. It is:
1. Batsim -> Simulates everything.
2. A scheduler -> Takes the decisions.

***** To see everything running, we can use 2 windows, one for each thing.
*NOTE:* Here, everything was setted to be in the /tmp.

#+NAME: batsim-side
#+BEGIN_SRC <bash> 
  batsim -p /tmp/batsim-v3.0.0/platforms/cluster512.xml        
         -w /tmp/batsim-v3.0.0/workloads/test_batsim_paper_workload_seed1.json
         -e "/tmp/expe-out/out"
#+END_SRC
It will keep the batsim oppened, waiting for the scheduler.

#+NAME: scheduler-side
#+BEGIN_SRC <bash>
  robin generate ./expe.yaml       
                    --output-dir=/tmp/expe-out       
                    --batcmd="batsim -p /tmp/batsim-v3.0.0/platforms/cluster512.xml 
                 -w /tmp/batsim-v3.0.0/workloads/test_batsim_paper_workload_seed1.json 
                 -e /tmp/expe-out/out"       
                    --schedcmd='batsched -v easy_bf'
#+END_SRC 
 It will use robin to run the scheduler batsched with the mode easy_bf.
*** pybatsim
**** Runs a schedular for the batsim.
**** Configuration
***** To install by: pip install pybatsim
***** To clone [[https://gitlab.inria.fr/batsim/pybatsim][PyBatsim-repository]] to have access to the schedulers implemented there.
**** To run its scheduler:
***** To run the batsim as the same way.
***** To run the schedulers, acess the repository and try:
****** pybatsim schedulers/scheduler.py
***** I tried:
****** pybatsim schedulers/fillerSched.py
****** pybatsim schedulers/schedFcfs.py
*** statistics
**** The batsim mainpage offer a example of statistic analysis:
#+BEGIN_LaTeX

#+END_LaTe
#+BEGIN_LaTeX

#+END_LaTeX
 #+NAME: batsim-analysis
 #+BEGIN_SRC sh
 #!/usr/bin/env Rscript
  library('tidyverse') # Use the tidyverse library.
  theme_set(theme_bw()) # Cosmetics.

  jobs = read_csv('out_jobs.csv') # Read the jobs file.

  # Manually compute some metrics on each job.
  jobs = jobs %>% mutate(slowdown = (finish_time - starting_time) /
                                  (finish_time - submission_time),
                       longer_than_one_minute = execution_time > 60)

  # Manually compute aggregated metrics.
  # Here, the mean waiting time/slowdown for jobs with small execution time.
  metrics = jobs %>% filter(longer_than_one_minute == FALSE) %>%
    summarize(mean_waiting_time = mean(waiting_time),
              mean_slowdown = mean(slowdown))

  print(metrics) # Print aggregated metrics.

  # Visualize what you want...
  # Is there a link between jobs' waiting time and size?
  ggplot(jobs) +
    geom_point(aes(y=waiting_time, x=requested_number_of_resources)) +
    ggsave('plot_wt_size.pdf')

  # Is this still true depending on job execution time?
  ggplot(jobs) +
    geom_point(aes(y=waiting_time, x=requested_number_of_resources)) +
    facet_wrap(~longer_than_one_minute) +
    ggsave('plot_wt_size_exectime.pdf')

  # Is there a link with job size and execution time?
  ggplot(jobs) +
    geom_violin(aes(factor(requested_number_of_resources), execution_time)) +
    ggsave('plot_exectime_size.pdf')

 #+END_SRC
**** Running this analysis on both pybatsimexamples we can check the different results.

** monday, 11-02-2019

*** DONE To understand:
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-11 seg 17:07]
:END:      

**** DONE The INPUT format for batsim;
:LOGBOOK:  
- State "DONE"       from "CANCELLED"  [2019-02-11 seg 17:07]
:END:      

**** DONE Some schedular examples;
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-11 seg 17:07]
:END:

*** The workflow:

**** Batsim-Scheduler communication:

***** Messages, JSON, via request-reply model:

****** Contraints format:

******* now

******* events

******** timestamp

******** type

******** data

******* And to differ the message, we change the *event type* as :

******** BIDIRECTIONAL

******** BATSIM => SCHEDULER

******** SCHEDULER => BATSIM

***** Workload:

****** The workload is an Input combined as:

******* Jobs: Users requests. It has:

******** id, subtime, res, profile, walltime, +
******* Profiles: Defines how the job execution should be simulated. It has:
******** type, etc. Where the type could be:
********* delay, prallel task, homogeneous pararllel task, etc.

**** Batsim requires to start:

***** a plataform; a workload; an output folder.

****** Providing a worload, it will have the jobs that should be scheduled.

***** Then, batsim will be learning, waiting for a scheduler to manage the jobs.

**** The scheduler:

***** Once the Batsim is already runnig, when we run the scheduler it will communicate with the Batsim by the messages, doing the requested decision.

***** The schdulers should implement all possible actions asked by the message types. For example: JobInitialize,kill,resquest. onBatSimInit,onJobSubmission, onJobCompletion.
**** An example:

***** I understood the fillerSched.py scheduler. It works following:

1. Initialize everything after Batsim intialized.
2. Schedule the jobs.
 2.2 _OnAfterBatsimInit_: // _Read_ a list of jobs *OpenJob* and a list of resources *availableResources* 
 2.1 _scheduleJobs_: // _Check_ all jobs in *OpenJob*
   2.1.1 _if_ (job.resourcesRequested > *aivailableResources*)
            discard it and remove from the *OpenJob*
   2.1.2 _else_
            scheduleJobs.append(job)
            *availableResources* -= jog.resourceRequested
            updateConsumptionTime
 2.2 _OnJobSubmission_:
  2.2.1 openJob.add(job)
  2.2.2 scheduleJobs()
 2.3 _OnJobCompletion_:
  2.3.1 *availableResources* += job.resourceRequested
  2.3.2 scheduleJobs()
***** I ran it as:
batsim -p platform52.xml -w test_batsim_paper_workload_seed1.json -e test-out-2
launcher.py scheduler/fillerSched.py

** tuesday, 12-02-2019
*** DONE on Batsim
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:18]
:END:      
**** DONE Check about the data asked for the jobs. How to locate or transfer it.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 08:57]
:END:
***** It is done by writing and checking the NFS file after and before to write or to remove some data from some QBox.
*** DONE on Papers
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:18]
:END:      

**** DONE Check on the Qarnot gitlab if there are some techniques for the schedulers.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:17]
:END:

***** There is a Deliverable2.2a that show the algortith to be implemented.
**** DONE Search some papers for schedulers on Cloud Computing
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-13 qua 18:17]
:END:      
*** TODO Source block configuration orgmode
:LOGBOOK:  
- State "TODO"       from ""           [2019-02-12 ter 12:54]
:END:
*** TODO ESS library
:LOGBOOK:  
- State "TODO"       from ""           [2019-02-12 ter 12:56]
:END:
** wednesday, 13-02-2019
*** Qarnot meeting
**** Administrative and update things with other teams.
**** About my part I should finish the current version of the QNodes scheduler. This way we will have a full system working.
**** With a full system working we will submit a paper to *SC2019*.
*** Papers and techniques
**** I read the both papers that I selected on 06-02 and 12-02 and selected some algorthms to check later.
**** But, as our plan now is to finish the current scheduler version, I will work on the current code and think about improvements after (aka. read about techniques now).
** REPORT I worked, mainly, understanding the problem and the behvaior. :WeekReview:
* Week 14-02 / 20-02
** thursday, 14-02-2019
*** DONE Modify the schedulers on pybatsim and compare the differences.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-15 sex 10:47]
:END:      
 I did it on the fillerSched. Now I will start to try to write a pseudocode for the QNodes scheduler.
** friday, 15-02-2019
*** I should implement the algorithm of the Deliverable 2.2a. But, it asks for a function to predict the time to download a dataset for a specific QBox.
*** I asked to Alex, by Slack, and he answered me that they do not have idea how to implement it now. So, I should skip it now, and after choose another rule to use.
*** DONE Start to write a pseudocode to the algorithm on dlv.2.2a. 
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-15 sex 21:21]
:END:      
**** def schedule(self, job): 
        print("Haaaaaaaaaaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeey-------\n")
        
        print("Job: ", job.id)
        print("Subtime: ", job.submit_time)
        print("Job.profile", job.profile)
        print("Profile", type(self.bs.profiles))
        list_of_datasets = {}
        for key in self.bs.profiles:
            print(self.bs.profiles[key][job.profile]['datasets'])
            qbox_key = job.profile
            list_of_datasets[qbox_key] = self.bs.profiles[key][job.profile]['datasets']

        for s in self.storage_controller._storages:
            st = self.storage_controller.get_storage(s)
            print("Datasets on Qbox: ", st.get_datas
**** It is current : 
***** getting the datasets asked by a job
***** listing all the storages on the StorageControl and its datasets.
*** 
*** TODO Talk with Clement
**** nix-shell https://github.com/oar-team/kapack/archive/master.tar.gz -A pybatsim
**** Cant found batsim using it.
**** 
**** On the batsim command: --events ../events/greco/events.json . There is no events.json on the folder.
**** 
**** Should I populate the Storage on the QNodeSched?
** monday, 18-02-2019
*** I finished my first version of the list of QBoxes that already has the specified dataset.
*** DONE 
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-19 ter 10:46]
:END:      
**** DONE Ask Clément
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-19 ter 10:45]
:END:      
***** Should I consider only one dataset per job and profile?
****** If more than one dataset per job: Should I do a matrix of QBoxes that has each dataset and chose the one that has more datasets?
****** No.
***** Should I consider a dataset as ["ds1"] or at the presented way ["QB...:inpu, QB:...:0, QB...:..."] ?
***** Can I commit and push my modifications in my branch on github?
****** Yes.
***** Mainly, I should put in the List only the QBoxes that already have ALL the required datasets from a job.
** tuesday, 19-02-2019
*** TODO
**** Check to put the list_qboxes_with_datasets() on the StorageController.
**** Dispatche some jobs to some QBoxes to test.
** wednesday, 20-02-2019
*** I attended the presentation:
**** David Shmoys: Models and algorithms for the Operation and Design of Bike-Sharing System
*** I finished my report to HPC course.
** REPORT I kept working to understand the environment and to learn how to use the Batsim and PyBatsim. :WeekReview:
* Week 21-02 / 27-02
** thursday, 21-02-2019
*** Checked one more time the function to do the list L (the list of qboxes that already has the required datasets)
*** Try to submitt the jobs to the QBoxes.
**** Here, the QNode uses onSubmission(job) to send it to the QBox.
**** It is receiving the message JOB_REJECTED. Maybe I need to use the "events" to change the event type of the jobs.
*** Algorithm
**** Im thinking in:
***** for each job j:
****** sched = True
****** l = L(j)
****** if l != null:
******* qbox = maxHeatingReq(l):
******* if qbox == null:
******** qbox = l [ 0 ]
****** else :
******* qbox = maxHeating()
******* if qbox == null:
******** sched = False
****** if sched:
******* qbox =  max_requiringHeating()
****** else:
******* waitingList.append(j)
***** 
** friday, 22-02-2019
*** TODO Verify how to:
**** DONE How to run a job, and why mine are been rejected?      :Clément:
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-25 seg 11:05]
- State "WAITING"    from "TODO"       [2019-02-25 seg 11:05] \\
  Ignore it now. I will start to work in the last version of the code.
:END:      
**** DONE Verify how to manage the instances of a job            :Clément:
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-25 seg 11:05]
- State "WAITING"    from "WAITING"    [2019-02-23 sáb 04:08] \\
  I need to confirm, but, as I understood, in the workload we have jobs like: 
    job 0 = {id=codeX-0 ...} job 1 = {id=codeX-1 ...} ... Job n = {id = codeX-n} }
  So, each job with id started with "codeX" , for real, are tasks for the same job.
  So, a job could be a unique job, or, if are composed by others, its not a job, it is a task.
  Then, we read the jobs as QTask().

  *YES*

- State "WAITING"    from "TODO"       [2019-02-22 sex 15:06] \\
  Is each instance a QTask on the new qarnotQNodeSched?
:END:
**** DONE Why the QTask now? What did change?                    :Clément:
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-25 seg 11:05]
- State "WAITING"    from "WAITING"    [2019-02-23 sáb 04:12] \\
  As I commit above, I think that these Taks are jobs that composes other bigger jobs.

  *YES*
:END:      
**** DONE Verify which qbox had preemption
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-02-25 seg 11:05]
- State "WAITING"    from "TODO"       [2019-02-23 sáb 04:14] \\
  I need to confirm. But as I understood. There are nothing registrating if some QBox has preemption.
  By definition, preemption occurs when some executing job is stopped because another one with more priority arrives.
  I think I need to check, by the priority of each job, if I would put the current job in some QBoxes, 
  it would cause a preemption. So, I need to check the priority of the jobs that are already runnig in that QBox.

  *YES*
:END:
**** WAITING Verify the qbox that require more work for the next hour
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-22 sex 10:49] \\
  I did it, but not for the next hour exactly. I do not know how to check it.
  Also, I need to test it, but I do not know how to add heating requirement to a qbox.

  *??* CHECK IT
:END:
** saturday, 23-02-2019
*** I think I understood some previous questions. They are in the TODO list of last day. So, I noted there what I think tha I understood.
** sunday, 24-02-2019
*** I changeg the workload in use, putting the "real data" from the qarnot-examples.
*** I started to do a function to get all indexes of jobs that compose the same main job.
**** This way, each job is thinked as a task, then, the idea is to dispatch as many as possible taks to the same qbox.
** monday, 25-02-2019
*** I will start to work with the last version of the scheduler in the pybatsim-temperature branch.
*** It uses QTask as the read input from the workload (aka. each input is a task and many tasks compose a job).
*** This new one are implement almost the scheduler of the delivrable 2.2a. Like:
*** TODO Algorithm peaces:
**** WAITING L <- List of QBOX that already has the required dataset. :Andrei:
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-25 seg 11:19] \\
  It is done in the previous scheduler. I should put it in the new one.
:END:      
**** WAITING Dispatch as many instances of j as possible on the selected QBox. :Clément:
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-25 seg 11:20] \\
  Almost done. I should check.
:END:      
**** WAITING Check the priority to QBoxes that have available QRads without preemption. :Clément:
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-25 seg 11:20] \\
  It is almost done. I should check.
:END:      
**** TODO Check the QBoxes that requires the most work in the next hour. :Qarnot:
**** TODO Download time prediction of the datasets                :Qarnot:
**** TODO LQ <- List of QBoxes sorted as 1. and 2.
***** WAITING 1. The count of available QRads for the priority of j in descending order. :Clément:
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-02-25 seg 11:20] \\
  It is almost done. I should check it.
:END:      
***** TODO 2. The predicted downloads time of the datasets.      :Qarnot:
*** Andrei's algortihm:

'''
The idea is to order a waiting list of tasks by the profile.
Then, find a list of qboxes that already has the required data set. 
Then, for each qbox in this list, dispacth as many tasks, of the same profile, as possible.
  If there are not enough qboxes to dispatch this tasks, find another options, with other rule.
Update the list and start for the next group (ordered by profiles) of tasks.
'''

 waiting_lits
 ordered_l = waiting_lists.orderedByProfile()
 nb = len(ordered_l)
 while (nb > 0):

   #The amount of tasks with the same profiles, counted by the beginning of the list, until the first task with a different profile.
   nb_same_profile = get_nb_same_profile(ordered_l) 
   
   qboxes_for_profile = L(ordered_l[ 0 ])

   for qb in qboxes_for_profile:
     nqb = qb.resources
     if (nqb >= nb_same_profile):
       dispatch(ordered_l[0:nb_same_profile], qb)
     else:
       dispatch(ordered_l[0:nqb], qb)
       nb_same_profile -= nqb
       ordered_l = ordered_l[nqb:]
   
   if(nb_same_profile > 0):
     findQBoxAndDispatch()
     ordered_l = ordered_l[nb_same_profile:]
*** New command                                                   :OrgMode:
**** To find and replace text: M + %
** tuesday, 26-02-2019
*** DONE Implement the previous algorithm
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-26 ter 18:42]
- The structure are done. But BATSIM is not working with this version of scheduler. 
  So, I need to wait the fixes to check.
:END:
** wednesday, 27-02-2019
*** TODO Work on
**** DONE the priority of QBoxes that have available QRads without preemption
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-01 sex 15:43]
:END:      
***** (aka. Run the taks using the priority levels: background, low and high.
**** CANCELLED the priority of QBoxes that requires the most work in the next hour
:LOGBOOK:  
- State "CANCELLED"  from "TODO"       [2019-02-27 qua 11:10]
:END:      
***** (skip it now)
**** DONE the count of available QRads for the priority of j in descending order
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-01 sex 15:44]
:END:      
***** (aka. The same as the first TODO)
**** WAITING the predicted download time of the data sets.
:LOGBOOK:  
- State "WAITING"    from "CANCELLED"  [2019-02-27 qua 11:10] \\
  Waiting the other team develop it.
- State "CANCELLED"  from "TODO"       [2019-02-27 qua 11:10]
:END:
**** DONE To merge my modifications on the StorageController with the Clément temperature branch.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-02-27 qua 17:17]
:END:      
**** DONE Organize the code. Use the doDispatch() as the main peace of the method schedule(). At the moment, it is duplicated.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-01 sex 15:44]
- [01-03-2019] As I found the error, I rewrote the code.
:END:
** REPORT I did the first steps on my implementation             :WeekReview:
* Week 28-02 / 06-03
** friday, 01-03-2019
*** I found an error in my last algorithm.
*** Let's rewrite it. Done.
*** Clément fixed batsim and changed something in the QNodeSched. I merged the codes.
*** TODO Check on next monday, how to run this version ?
** saturday, 02-03-2019
*** I added the structure to use the predicted download time of the data sets, when it is ready.
** monday, 04-03-2019
*** DONE 
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-04 seg 18:23]
:END:      
**** DONE Run the updated batsim and qarnotNodeSched.py
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-04 seg 18:22]
:END:      
***** To run it, I copied the folder sample-data/simple from simulator-prototype to batsim to make it easier.
***** The command is: ./batsim -p ../sample-data/simple/platform_simple.xml -T 1 --enable-dynamic-jobs --events ../sample-data/simple/events_simple.json -w ../sample-data/simple/workload_simple.json
**** DONE Try to run mine and correct the possible *errors*
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-04 seg 18:22]
:END:      
***** DONE To decide if I will create a QTask using the job.profile, or if I will get it after using the task.job_id :Clément:
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-04 seg 15:47]
- I choose to add into the QTask() the profile. I should merge it with the main qarnotBoxSched.py
:END:
*** I got a little error in the qarnotNodeSched.py. It is getting the number of slot of bkgd, low or hight priority for each qmobo :Clément:
*** but, it is not verifying if the value is zero. So, the execution have never passed from the first priority case, bkgd.
**** Clément already fixed it in his official version.
*** I ran my first version of the scheduler !!!!!!!!!!!!!!  
**** It is working.
**** I generated the csv files to it and to the qarnotNodeSched to try to compare some values:
***** The allocated_resources in the _jobs.csv changed. Mine has in almost the cases, less allocation.
***** If I understood well, it shows how many resources were allocated for each job. So, it show that mine is allocating less resources,
***** I am concluding it means that the allocation decision is working, and the tasks or jobs with the same profile (the tasks that composes the same job) are not allocating new resources everytime.
**** Now, the next step is to check some more workloads and really compare the performance with the official one.
** tuesday, 05-03-2019
*** TODO To Compare the results
**** DONE First point: [Evalys][[https://gitlab.inria.fr/batsim/evalys]]
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-05 ter 18:28]
- It shows some parameter for the jobs and workload. Using it right now, I am looking to the Gantt Chart to see how the tasks are beeing scheduled.
:END:
**** TODO To compare the temparatures at the beggining and end of the simulation.
*** Presentation: *Parallel Scheduling of DAGs under Memory Constraints* :Presentation:
**** Use DAGs to describe
**** Problem: Shared memory (Limitade resources)
*** TODO To check the code
**** I am build the list L before checking all states (bkgd, low and high). It is not wrong for results, but maybe I could do only one time and get a better performance.
*** Results                                                           :ATTACH: :ATTACH:

:PROPERTIES:
:Attachments: qarnotNodeSchedAndrei_jobs_results_first.png qarnotNodeSchedAndrei_jobs_results_first_second.png qarnotNodeSchedAndrei_jobs_results_triplet.png qarnotNodeSched_jobs_results.png qarnotNodeSchedAndrei_jobs_results_first13.png qarnotNodeSchedAndrei_jobs_results_first_triplet.png qarnotNodeSchedAndrei_big_jobs_results_first_triplet.png qarnotNodeSchedAndrei_big_jobs_results_first.png qarnotNodeSched_big_jobs_results.png
:ID:       88869df9-d5d4-400e-b11e-b8e41a439426
:END:
 
To compare the difference between the qarnotNodeSched and my implementation I am running the same workload for both and then, I am using the evalys to plot some results and compare it.
For the first moment, I ran the simple wokload, with 8 jobs, and 2 QBoxes which has 7 and 3 QMobos each one.
I got the following results:

First of all, the current scheduler does not use anything about location, neither download or transfer data sets to the QBox where the tasks are dispatched.
It just simulate the job's execution but does not do nothing about the data managment.
So, to check my scheduler, I am adding at the beggining of the simulation some data sets in some QBoxes.
My implementation check if exists a list (L) of QBoxes that already have the required data sets. Then, dispatch the tasks considering this list (L) and the status of the Mobos into the QBoxes (bkgd, low and high).
If L is empty it just consider the status of the Mobos, as the current scheduler.

Here we have the plots for the current qarnotNodeSched:
#+NAME: fig:0
#+ATTR_ORG: :width 700px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSched_jobs_results.png]]

Note that we have tasks from the same job scheduled to different QBoxes.

Now, for all plots, I am adding data sets in some QBoxes, which will change plot by plot.
I will use q1 to the qbox above and q2 to the qbox under:

_______________________________________________________________


DATASET_ADDED: first on q2

#+NAME: fig:1
#+attr_org: :width 500px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_jobs_results_first.png]]

We can see that all first tasks came down.
______________________________________________________________

DATASET_ADDED: first and second on q2

#+NAME: fig:2
#+attr_org: :width 500px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_jobs_results_first_second.png]]

We can see that all first tasks came down, as the second task.
_____________________________________________________________

DATASET_ADDED: triple on q2

#+NAME: fig:3
#+attr_orf: :width 500px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_jobs_results_triplet.png]]

We can see that all triplet tasks came down.

DATASET_ADDED: first on q1

#+NAME: fig:4
#+ATTR_ORG: :width 500px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_jobs_results_first13.png]]

We can see that all first tasks goes up.

______________________________________________________________

DATASET_ADDED: first and triplet on q2

#+NAME: fig:5
#+ATTR_ORG: :width 500px
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_jobs_results_first_triplet.png]]

We can see that all triplet taks came down, as the first tasks.
_______________________________________________________________

*Looking to the dataset from the Qarnot extractor: 1-day*:

Simulating with the current scheduler:

#+NAME: fig:6
#+ATTR_ORG: :width 500
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSched_big_jobs_results.png]]

________________________________________________________________

Now, simulating with my scheduler, adding some datasets we can se the follow plots:

DATASET_ADDED: one randomly 

#+NAME: fig:7
#+ATTR_ORG: :width 500
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_big_jobs_results_first.png]]

_________________________________________________________________

DATASET_ADDED: two randomly

#+NAME: fig:8
#+ATTR_ORG: :width 500
[[file:data/88/869df9-d5d4-400e-b11e-b8e41a439426/qarnotNodeSchedAndrei_big_jobs_results_first_triplet.png]]


For both we can see modifications in the GANTT Chart. As it has a lot of information, it is not so clear to read. 
But we can see the behavior changing in order of the data sets modifications.
_________________________________________________________________

So, I am concluding that my implementation are working in the sens of take care about the location of the data sets that already exists on the QBoxes. :)

** wednesday, 06-02-2019
*** Meeting about the project
**** Continue working on my implementation
**** Pierre's feedback: Try to draw an overview of the actions
***** Like this diagrams:                                        :ATTACH:
:PROPERTIES:
:Attachments: diagram%20model1.jpeg diagram%20model2.jpeg
:ID:       336b7389-3c9a-47f4-af8e-473d7e0891a6
:END:

#+ATTR_ORG :width 200
[[file:data/33/6b7389-3c9a-47f4-af8e-473d7e0891a6/diagram model1.jpeg]]

#+ATTR_ORG :width 200
[[file:data/33/6b7389-3c9a-47f4-af8e-473d7e0891a6/diagram model2.jpeg]]

*** TODO 
**** WAITING To talk with Alex to get the current state of the StorageController
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-03-29 sex 11:39]
:END:      
**** DONE To talk with Pierre to check the worflow and how to analyze the temperature
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-06 qua 16:21]
- We will aks the other team to extract this data from the DB. And so, I can check and plot it.
  It will be a plot like: 3 lines, 1 from the real Qarnot data, 1 from each scheduler. So, it will possible to compare which one is better at this sense.
:END:      
**** DONE To generate different kinds of workloads (more taks than resources) to test it.
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-03-29 sex 11:39]
- State "WAITING"    from "TODO"       [2019-03-06 qua 16:23] \\
  The generator uses the real Qarnot Serves/DB, it is so busy now.
:END:

** REPORT I finished the my first version, calculated some results and presented it. :WeekReview:
* Week 07-03 / 13-03
** thursday, 07-03-2019
*** TODO
**** DONE To make the qarnotScheduler works with 1week workload  :Clément:
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-03-29 sex 11:31]
- State "WAITING"    from "TODO"       [2019-03-07 qui 17:34] \\
  Almost done. 
  * We added one more line in the QBoxSched, it was a "gambiarra". We should implement the 're-schedule' there.
:END:      
**** DONE To get one day more of simulation data using the qarnot-extractor
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-03-29 sex 11:31]
- State "WAITING"    from "TODO"       [2019-03-07 qui 17:31] \\
  Still waiting for a good moment.
:END:      
**** DONE To generate a bigger workload 
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-07 qui 17:31]
- I took the 1 day workload and removed many Qboxes. Now it has more jobs than resources.
:END:      
***** TODO To put two days together
***** TODO TO try to do something like this with the simple workload
*** I also changed the simple workloads. Now it has 4 Mobos and so, jobs are been rejected.
*** It still allocate the jobs as the data set location, but, if there ia a conflict in the submission time with another task,
*** it is rejected.
*** DONE To check with Clément this rejections. I think the jobs should be reeschedule, but we do not have it yet, I think.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-08 sex 10:47]
It happened because the 'gambiarra' that we did to try to run the 1-week workload.
:END:      
** friday, 08-03-2019
*** TODO
**** TODO Implement the re-schedule method.
***** The QBoxes should 'reject' and so, the QNode should put it again in the waiting_list.
***** It is already implemented, but it is confuse because it adds and removes from differente instances of the waiting_list and is getting error because are deleting more than adding.
****** So, I will try to create a reject_list to manage during some bigger step, then put it back on the wainting list.
** sunday, 10-03-2019
*** To continue testing the case of workloads failing.
*** DONE 
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-10 dom 20:49]
:END:      
**** DEFERRED Create a new workload, smaller, but also with more taks than resources.
:LOGBOOK:  
- State "DEFERRED"   from "DONE"       [2019-03-10 dom 20:49]
- State "DONE"       from "TODO"       [2019-03-10 dom 20:49]
:END:      
**** DONE Organize the prints to output
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-10 dom 20:49]
:END:      
*** To try to do some automatic tests for different workloads
*** TODO Correct: Possible Bug's list
**** TODO The taks are not removed from the queue_task after dispatched. Only onJobCompletion(). This way, every doDispatch() try to re-dispatch all taks. 
***** Which does not happen because the number of instances for them is 0. But, anyway, doDispatch() consume times trying to do it.
**** DONE When a job is rejected, the number_instances_left is not increased.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-10 dom 21:21]
:END:      
**** DONE When a job is rejected, the num of available_mobos in tup[] is not increased.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-10 dom 21:21]
:END:       
**** TODO On the QBoxSched:
***** On onDispatchedInstances() :
****** The method scheduleInstace() are receiving the waiting_instances duplicated. So, it is happening in the onDispatchedInstances() at some point.
***** It prints "Still have x instances" already with the duplicated list. 
***** It is possible to be verified printing the waiting_list between the logs "received x intances" and "still have x instances".
**** TODO To verify the mapToQbox() and then implement a removeFromQBox().
** monday, 11-03-2019
*** Some Corrections
**** There was an error on JobCompletion(). It was direct dispatching a job, but was not adding it in the qtask.running_instances.
***** Solved.
**** REPORT There was a Bug on the updateAndReport() on the QBox level. It was getting wrong the available resources, then inform wrong values to the doDispatch() on the QNode level.
:LOGBOOK:  
- State "REPORT"     from ""           [2019-03-29 sex 11:35]
:END:      
***** Because it, NodeSched was dispatching more tasks than possible, making the QBox creates a waiting_instances list.      
***** It was corrected and now the doDispatch are sending valid amount of tasks to each QBox. 
**** In the simple_more workload, the triplet_ tasks are not ending. It is dispatched but have never end. Then, Batsim becomes in deadlock.
***** I changed the priority value of triplet_ from -5 to 15 and it works well for this case. 
**** For 1 week it still not working.
**** DONE To check the priority conditions.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-12 ter 16:36]
- The problem was the direct_dispatch().
- In the availableResouces check().
:END:      
** tuesday, 12-03-2019
*** Experiment table design

| *Workload*  | *Workload* |  *Workload* | *Status*          | *Status*                | *Status*           |
| *Name*      |    *Tasks* | *Resources* | *qarnotNodeSched* | *qarnotNodeSchedAndrei* | *Final allocation* |
|             |            |             |                   |                         |                    |
| simple      |          8 |          10 | PASS              | PASS                    | MODIFIED           |
| simple_more |          8 |           4 | PASS              | PASS                    | MODIFIED           |
| 1day        |        418 |        1000 | PASS              | PASS                    | MODIFIED           |
| 1day_more   |        418 |         724 | PASS              | PASS                    | MODIFIED           |
| 1week       |       3010 |         991 | PASS              | PASS                    | MODIFIED           |
| 1week_more  |       3010 |           x | PASS              | WAITING                 |                    |
|             |            |             |                   |                         |                    |
*** The simulation ran correclty wihtou the direct_dispatch(). So we will will keep like this for the momento and try to re-implement it.
** wednesday, 13-03-2019
*** Qartnot meeting
**** WAITING Checks 
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-03-29 sex 11:36]
:END:      
***** DONE To check with Alex the status of the StorageController
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-03-13 qua 10:25]
- State "WAITING"    from "TODO"       [2019-03-13 qua 10:22] \\
  They have something done, but did not push yet.
:END:
**** SC is too near, so we will drop :(
**** The goal is to finish a full implementation until April 16,17 and then, to build a full paper describing the platform.
**** ClustComput could be a conference to apply. https://clustercomp.org/2019/technical/

*** TODO Next steps
**** TODO Comparison for job locations
***** TODO Different workloads
***** TODO Set automatically when Alex finished the StorageController
**** TODO Comparison for the temperature
***** TODO Implements first versions
**** TODO Presentation of the scheduler
***** TODO Draw the workflow
**** TODO Organize my workflow with batsim aka. run_scripts and results
*** Im looking conferences
**** http://www.lanoms.org/2019/#topics
***** Smart Devices and Home Networks
***** Smart Cities, Smart Grids
***** 
**** http://sbqs.sbc.org.br/index.php/pt/chamada-de-trabalho
**** https://webmedia.org.br/2019/
**** http://www.inf.ufrgs.br/er2019/
*** DONE Master2 -> Register my presentation in June with an external expert.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-13 qua 14:14]
:END:      
**** Title: Job allocation in a distribued private cloud
**** External Expert: Christophe Cérin
** REPORT I worked testing both implementation with different workloads. This way I found problem in the main implementation. :WeekReview:
** REPORT It was not working with workloads composed by more jobs than resources. :WeekReview:
** REPORT The problem was the direct_dispatch(), then I commented it for the moment, and I checked both implementation with the 1day and 1week workloads. :WeekReview:
** REPORT Both ran and the location-based implementation is working as well. :WeekReview:
* Week 14-03 / 20/03
** thuersday, 14-03-2019
*** I have started to draw the scheduler workflow
** friday, 15-03-2019
*** I discussed with Clément some components and versions of the diagram and then finish a first version.
*** I made the detailed description of all steps.
*** I showed and discussed improvements with Pierre.
** saturday, 16-03-2019
*** I drew a new version of the diagram, regarding the real components instead of the simulation.
** monday, 18-03-2019
*** WAITING Discuss and repair the new draw
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-03-19 ter 10:27] \\
  I showed it to Denis and did few repairs.
:END:      
*** WAITING Check updates on the StorageController implementation, if any.
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-03-19 ter 10:27] \\
  Clément will check the merge requested form Alex.
:END:
** tuesday, 19-03-2019
*** DONE Check the repairs in the NodeSched, on directDispacth(), and run all workloads.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-19 ter 16:32]
:END:
*** WAITING Use the .csv about the temperature on the platform-extractor to measure the difference of the final temperature between NodeSched e NodeSchedAndrei.
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-03-19 ter 16:32] \\
  I draw two plots and have been started to script it.
:END:      
**** Im thinking to do 2 kinds of plots:
***** 1. For a selected QRad, plot the time on axe x and the temperature on axe y for the three data source (real, sched, schedAndrei)
***** 2. For all QRads, plot the BoxPlots (for whole data source) on axe x, and the temperature on axe y.
**** BUT, there are 228 jobs for 1022 QRads, how to plot for all? How to select which one to plot?
*** I also showed the new version of the diagram (focused on the real platform and componenets).
**** He adviced me to keep both, onde for the simulation and onde for the real platform).
**** He advided me to separate more the component and the lines and explicit more somethings.
** wednesday, 20-03-2019
*** DONE The script to analyze the _temperatures.csv with R.
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-04-02 ter 14:42]
- State "WAITING"    from "TODO"       [2019-03-20 qua 16:14] \\
  In progress..
:END:      
**** Installed: r-base, r-studio, ess
**** This link shows something like I want to do : https://stackoverflow.com/questions/14604439/plot-multiple-boxplot-in-one-graph
***** It uses the function 'melt'. Here I found some details https://www.statmethods.net/management/reshape.html
*** DONE Finalize a first version of diagrams.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-20 qua 16:14]
I showed to Pierre and modified some more details. Shower do Clément and Denis also. So, the first version is done.
:END:      
** REPORT I have been waiting for the correction in the qarnotNodeSched and for the StorageController. :WeekReview:
** REPORT While it is not done I have been worked on the diagram. :WeekReview:
** REPORT Clément repaired the qarnotNodeSched then I merge it with my version. :WeekReview:
** REPORT Now we have the _temperature.csv as output of the simulation, then I also have been started to script the plot of the graphs to view the temperature behavior. :WeekReview:
** REPORT I finished the first version of the diagrams (real platform and simulations) :WeekReview:
* Week 21-03 / 27-03
** thuersday, 21-03-2019
*** DONE Check the rpy2
:LOGBOOK:  
- State "DONE"       from "WAITING"    [2019-03-28 qui 13:16]
- State "WAITING"    from "TODO"       [2019-03-21 qui 16:20] \\
  The installation failed.
:END:      
*** I started to use the Jupyter Notebook with R to plot the results.
**** The problem is that the two .csv are not of the same dimension and the rads are not ordered at the same way.
**** So, I'm trying to get the same times and order at the same way.
** friday, 22-03-2019
*** Pedro helped me a lot, he taught me many things in R and many ways to plot what I want.
library(dplyr)
library(tidyr)

set.seed(1234)

df$origin <- "simulation"
df2$origin <- "real"

df3 <- df2[ , names(df2) %in% names(df)]
df_all <- rbind(df, df3) 

#str(df_all)
#names(df_all)[3]
#tail(names(df_all), 1)
df_all_melted <- gather(df_all, factor_key = TRUE, key = "machine", value = "temperature", QRAD.0400.91a3.6f05.000000000000:QRAD.adf0.074e.5988.000000000000)
#str(df_all_melted)

#sample(levels(df_all_melted$machine), 10)
#df_plot <- subset(df_all_melted, machine %in% sample(levels(df_all_melted$machine), 300))

# aprender mutate & summarize
df_means <- df_plot %>%
    group_by(machine, origin) %>%
    summarize(temperature_mean = mean(temperature)) %>%
    ungroup()

#str(df_plot)
#str(df_means)

#str(df$timestamp)
#str(df2$timestamp)

# procurar como colocar o alpha da legenda = 1
ggplot(df_means, aes(y = temperature_mean, x = machine, color = origin)) +
    #geom_jitter(width = 0.2, alpha = 0.1) +
    geom_point(alpha = 1.0) +
    theme_bw() +
    theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
*** gather 
 Gather takes multiple columns and collapses into key-value pairs, duplicating all other columns as needed. You use gather() when you notice that you have columns that are not variables.
 https://www.rdocumentation.org/packages/tidyr/versions/0.8.3/topics/gather
*** sample
sample takes a sample of the specified size from the elements of x using either with or without replacement.
 https://www.rdocumentation.org/packages/base/versions/3.5.3/topics/sample
*** jitter 
 The jitter geom is a convenient shortcut for geom_point(position = "jitter"). It adds a small amount of random variation to the location of each point, and is a useful way of handling overplotting caused by discreteness in smaller datasets.
 https://ggplot2.tidyverse.org/reference/geom_jitter.html
*** means and error bars
http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)
*** others
https://stackoverflow.com/questions/16251966/controlling-the-alpha-level-in-a-ggplot2-legend
http://www.sthda.com/english/wiki/ggplot2-axis-ticks-a-guide-to-customize-tick-marks-and-labels
https://felixfan.github.io/ggplot2-remove-grid-background-margin/
https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf
rcolorbrewer scales
*** TODO to check mutate, summarize, ggrepel
*** TODO to search how to put alpha of subtitles = 1
** monday, 25-03-2019
*** DONE To finish the graphs.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-25 seg 11:26]
:END:      
**** CANCELLED To check if is possible to tag the used QRads by the csv.
:LOGBOOK:  
- State "CANCELLED"  from "REPORT"     [2019-03-25 seg 11:26]
- It is not necessary. The problem is the method to target temperature on the scheduler.
:END:      
**** To get the color :  https://www.datanovia.com/en/blog/top-r-color-palettes-to-know-for-great-data-visualization/
*** DONE To check the R + Python
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-28 qui 13:17]
:END:      
**** DONE To plot in the same jupyter notebook file: Gantt charts and temperature results.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-28 qui 13:17]
:END:      
*** DONE To check and fix the JobCompletio TODO in the NodeSched.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-02 ter 14:42]
:END:      
**** TODO On checkSimulationFinished() -> Its receiving from Batsim : NoMoreStatic and NoMoreExternal.
***** It makes sense, because when Batsim dispatch the last jobs could there are noMoreStatic or External. But, should we killorRejectAllJobs???
**** TODO On jobCompletion() -> If a job is COMPLETED_KILLED the task is killed.
***** We need to resubmit it. Maybe, we should create a new QTask , then kill the current one.
**** TODO To discuss with Clément the policies to reject a task, a job and to killOrRejectJobs()
*** DONE To export to jupyter notebook my script to plot the comparison between mine and Clément's implementation of the NodeSched.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-25 seg 18:33]
:END:
*** DONE To send the links of notebook files (temperature_analyzes and job_allocation_analyzes) to Pierre.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-25 seg 18:35]
:END:      
** tuesday, 26-03-2019
*** DONE To work on the scheduler
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-02 ter 14:43]
:END:      
**** DONE ReSchedule a job killed because it has lower priority than a new one.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-02 ter 14:43]
:END:      
**** The point is, now, it is killing the jobs regarding the simulation time, not the priority of the jobs.
**** BATSIM should recreate the job, neither PyBatsim !!!!
***** So, I need to do something to PyBatsim says to BatSim to recreate the Job.
***** I'm using bs.resubmit(job) and it looks working. When I filter the Batsim log by "resubmit" Im receiving 604 matching, the number of killed jobs.
***** I think that the real problem are in how the simulation are been finished.
***** TODO To check it.
*** I added a new plot for the temperature analyzes.
** wednesday, 27-03-2019
*** I used rpy2 to do a new Jupyter Notebook running Python and R code together. It already has the Job_Allocation and Temperature analyzes.
*** Working on simple workload with less resources, we are receiving rejected jobs.
**** Platform
{
    "qboxes": [
        {
            "wan_lat": "10ms",
            "lan_lat": "1ms",
            "qrads": [
                {
                    "qmobos": [
                        "MOBO-d5b0-27cc-5462-708bcdabae9f"
                    ],
                    "air_conduct_coeff": 10,
                    "cpu_type": "Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz",
                    "bw": "1Gbps",
                    "host_conduct_coeff": 1.6,
                    "lat": "100us",
                    "nb_mobos": 1,
                    "id": "QRAD-d5b0-27cc-5462-000000000000"
                }
            ],
            "lan_bw": "1Gbps",
            "name": "bnp-wai",
            "disk_size": "6e12",
            "wan_bw": "100Mbps",
            "id": "QBOX-bbbb-0000-0000-000000000001",
            "site": "paris"
        }
    ]
}
**** Events
{"timestamp": 0, "type": "qrad_set_target_temperature", "new_temperature": 22, "qrad": "QRAD-d5b0-27cc-5462-000000000000"}
{"timestamp": 0, "type": "site_set_outside_temperature", "new_temperature": 10, "site": "paris"}
{"timestamp": 0, "type": "site_set_outside_temperature", "new_temperature": 12, "site": "bordeaux"}
{"timestamp": 200, "type": "site_set_outside_temperature", "new_temperature": 15, "site": "bordeaux"}
{"timestamp": 500, "type": "machine_unavailable", "resources": ["MOBO-d5b0-27cc-5462-708bcdabae96", "MOBO-d5b0-27cc-5462-708bcdabacb6", "MOBO-d5b0-27cc-5462-708bcdabae9f"]}
{"timestamp": 1000, "type": "site_set_outside_temperature", "new_temperature": 15, "site": "bordeaux"}
**** Workload
{
    "nb_res": 1,
    "profiles": {
        "QJOB-first_0_profile": {
            "com": 0,
            "cpu": 437072.265625,
            "datasets": [
                "QJOB-first:user-input:540624",
                "QJOB-first:docker:162852561",
                "QJOB-first:user-input:41428146"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": 30
        },
        "QJOB-first_1_profile": {
            "com": 0,
            "cpu": 663829.78515625,
            "datasets": [
                "QJOB-first:user-input:540624",
                "QJOB-first:docker:162852561",
                "QJOB-first:user-input:41428146"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": 30
        },

        "QJOB-second_0_profile": {
            "com": 0,
            "cpu": 265625.0,
            "datasets": [
                "QJOB-second:user-input:41428146",
                "QJOB-second:docker:67221727"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": -5
        },

        "QJOB-triplet_0_profile": {
            "com": 0,
            "cpu": 124683.0,
            "datasets": [
                "QJOB-triplet:user-input:0"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": 10
        },
        "QJOB-triplet_1_profile": {
            "com": 0,
            "cpu": 125583.0,
            "datasets": [
                "QJOB-triplet:user-input:0"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": 10
        },
        "QJOB-triplet_2_profile": {
            "com": 0,
            "cpu": 126653.0,
            "datasets": [
                "QJOB-triplet:user-input:0"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": 10
        },

        "QJOB-long_115_profile": {
            "com": 0,
            "cpu": 709986.572265625,
            "datasets": [
                "QJOB-long:docker:1305968769",
                "QJOB-long:user-input:41428146",
                "QJOB-long:user-input:0"
            ],
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": -5
        },
        
        "QJOB-null-dataset_1_profile": {
            "com": 0,
            "cpu": 421967.13256835897,
            "datasets": null,
            "user": "unknown-user",
            "type": "parallel_homogeneous",
            "priority": -5
        }
    },
    "jobs": [
        {
            "subtime": 420,
            "res": 1,
            "profile": "QJOB-first_0_profile",
            "id": "QJOB-first_0"
        },
        {
            "subtime": 410,
            "res": 1,
            "profile": "QJOB-first_1_profile",
            "id": "QJOB-first_1"
        },
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-second_0_profile",
            "id": "QJOB-second_0"
        },
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-triplet_0_profile",
            "id": "QJOB-triplet_0"
        },
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-triplet_1_profile",
            "id": "QJOB-triplet_1"
        },
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-triplet_2_profile",
            "id": "QJOB-triplet_2"
        },
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-long_115_profile",
            "id": "QJOB-long_115"
        },   
        {
            "subtime": 0,
            "res": 1,
            "profile": "QJOB-null-dataset_1_profile",
            "id": "QJOB-null-dataset_1"
        }
    ]
}
**** Datasets
{"id": "QJOB-first:docker:162852561", "size": 162852561}
{"id": "QJOB-first:user-input:540624", "size": 43523021}
{"id": "QJOB-first:user-input:41428146", "size": 16336}
{"id": "QJOB-second:docker:67221727", "size": 162852561}
{"id": "QJOB-second:user-input:41428146", "size": 16336}
{"id": "QJOB-triplet:user-input:0", "size": 16336}
{"id": "QJOB-long:user-input:41428146", "size": 41428146}
{"id": "QJOB-long:docker:1305968769", "size": 262144}
{"id": "QJOB-long:user-input:0", "size": 32375882}
** REPORT I have continuing waiting for the StorageController implementatio. :WeekReview:
** REPORT I am debugging the last version of Clément and testing differente workloads. :WeekReview:
** REPORT I have started to work on the re-submition            :WeekReview:
** REPORT I fininshed the first plots for the temperature analyzes (1. looking for the means of all rads; 2. looking for whole data for some specific QRads) :WeekReview:
* Week 28-03 / 03-04
** thuersday, 28-03-2019
*** I was think about the energy consumption.
*** I corrected the analyzes on jupyter notebook using the Magic Commands. aka. %%command. To use rpy2 at the correct way.
*** Im reading the initial papers of the Qarnot description and the scheduler problem to start to think about my Objectives and Introduction for my final report.
*** I attended a presentation.
*** REPORT To Check: Is the availableMobos method working properly?? Because we are killing jobs but it shows available mobos !!! :WeekReview:
:LOGBOOK:  
- State "REPORT"     from "DONE"       [2019-03-29 sex 11:01]
- State "DONE"       from "TODO"       [2019-03-29 sex 11:01]
Yes, it was not working correctly. Clément fixed it.
:END:      
***** Line 337 - BoxSched: # Some instances were dispatched by cannot be started yet, return them to the QNode
** friday, 29-03-2019
*** DONE To check the train to Paris and send to samantha.sanchez@imag.fr
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-03-29 sex 11:01]
Asked for the same as Clément.
:END:
*** REPORT Algorithm: Available Resources
 - The method returns the number of available resouces (empty mobos or possible to be preempted).
 - For the first moment, all Mobos count on bkgd, because it depends on the temperature.
 - So, for example: 
   If we have only one Mobo in the QRad:
   At the first moment, it will return: bkgd/low/high : 1/0/0
   If we dispatch for this QRad a LOW priority job and ask the available resources, it should returns: 0/0/1
      The Mobo is running the job, but it is possible to be preempted by a HIGH priority JOB.
   If we dispatch for this QRad a HIGH priority job and ask the available resources, it should returns: 0/0/0
      Because a HIGH priority job can not be preempted.
 - Another example: QRad with 2 Mobos -> 2/0/0
   - Dispatch a LOW priority => 1/0/1
   - Dispatch a HIGH priority => 0/1/0
   - Dispatch a HIGH priority => 0/0/0
*** DONE Re-submission
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-02 ter 14:46]
:END:      
**** Without resubmition: 
simple: Job submitted: 8 , scheduled: 8 , rejected: 0 , killed: 2 , changed: 0 , timeout: 0 , success 6 , complete: 8
1 day: Job submitted: 221 , scheduled: 221 , rejected: 0 , killed: 0 , changed: 0 , timeout: 0 , success 221 , complete: 221
1 week: Job submitted: 11831 , scheduled: 11831 , rejected: 0 , killed: 501 , changed: 0 , timeout: 0 , success 11330 , complete: 11831
2 weeks : Job submitted: 15922 , scheduled: 15922 , rejected: 0 , killed: 588 , changed: 0 , timeout: 0 , success 15334 , complete: 15922

**** Looking to the flow of the process:
***** At the QBox side:
****** There is a job running in a QBox
***** At the QNode side:
****** The QNode dispatches to the same QBox a job with higher priority.
***** At the QBox side:
****** The QBox will kill the running task => Informs BATSIM.
****** The QBox will start to run the new task => Informs BATSIM.
***** At the BATSIM side:
****** BATSIM will take the killed task as COMPLETED_KILLED => Informs the QNode.
****** BATSIM will take the new task as RUNNIN (?? confirm the "therm")
***** At the QNode side:
****** The QNode will receive on JobCompletion the killes task as COMPLETED_KILEED.
****** TODO Then, we need to resubmit it.
**** TODO Change the event time to finish the simulation, the priority of the jobs, and etc, to force preemption situations.
*** TODO Energy Consumption plots
**** TODO To check the parameters
*** TODO Discuss the final status:
 Job submitted: 8 , scheduled: 2 , rejected: 6 , killed: 1 , changed: 0 , timeout: 0 , success 1 , complete: 2
 Here, 1 job was COMPLETED_SUCCESFULY, 1 killed because was running when BATSIM asked to finish the simulation, 6 rejected because were not scheduled before BATSIM ask to finish the simulation.
 So, my point is, the final status should be : rejected: 6, killed: 1, changed: 0, timout: 0, success 1, complete: 1.
 In my opnion, the "complete" does not make a lot of sense.
** sunday, 31-03-2019
*** Working on Re-submission
 Using a workload to enforce a preemption. It is possible to verify that the job is preempted, the new one starts to run and the previous run is killed.
 When the re-submission is done, the new job is created with '#' to be identified.
 Then all other job are been finished and the resubmitted dont.
 I think that the resubmission method just create the new job, but did not add send to pybatsim to be ran. 
 Two options:
 - To try to change the resubmission method.
 - To try to calls resubmission_job() and another method in batsim to ask the job execution.
 I also think that the resumission does not add the event: "EXECUTE_JOB", so it does not look like a job to be executed. Just some job that already ran or something like this.
 Opntio:
 - To try to modify the resubmission method to chang this value.
** monday, 01-04-2019
*** I filled the files to the Mission in Qarnot
*** Working on re-submission
 I have been done the methos in the NodeSched. It is called in the OnJobCompletion if(job.state == COMPLETED_KILLED).
 Then I'm creating a new job, register_job and copying the mainly values as profile, id, etc, and adding the field "metadata" with job_parent, nb_resubmitted ...
 It have been resubmitted, but, something is occuring when the resubmitted job is completed. Because is not possible to access the job.qtask_id when the job arrive on the jobCompletion.
** tuesday, 02-04-2019
*** Working on re-submission                                   :WeekReview:
 In the QBoxSched, when a subqtask would be created, it was considering a "dataset" list for all instances. But, for the empty one it was getting error. Clément fixed it.
 For the re-submission I created a new method on batsim.py to register a job resubmitted.
 OBS: The update_period defined in the qarnotNodeSched changes the decision, aka, changes the final status. 
      Ex: with the simple_more workload, update_period = [100, 140] => 1 killed job; update_period = [150,300] => 0 killed jobs.
*** Results:
**** period_time = 300
***** 2_week: Job submitted: 15922 , scheduled: 17323 , rejected: 0 , killed: 1424 , changed: 0 , timeout: 0 , success 15899 , complete: 17323
***** 1_week: Job submitted: 11831 , scheduled: 12738 , rejected: 0 , killed: 911 , changed: 0 , timeout: 0 , success 11827 , complete: 12738
***** 1_day: Job submitted: 221 , scheduled: 221 , rejected: 0 , killed: 0 , changed: 0 , timeout: 0 , success 221 , complete: 221
***** simple_more: Job submitted: 8 , scheduled: 8 , rejected: 0 , killed: 0 , changed: 0 , timeout: 0 , success 8 , complete: 8
**** period_time = 140
***** 1_week: Job submitted: 11831 , scheduled: 12784 , rejected: 0 , killed: 960 , changed: 0 , timeout: 0 , success 11824 , complete: 12784
***** 1_day: Job submitted: 221 , scheduled: 221 , rejected: 0 , killed: 0 , changed: 0 , timeout: 0 , success 221 , complete: 221
***** simple_more: Job submitted: 8 , scheduled: 9 , rejected: 0 , killed: 1 , changed: 0 , timeout: 0 , success 8 , complete: 9
*** TODO Add the following values in the final status: resubmitted and real killed (maybe, "preempted").
*** DONE Save the output of the simple_more with preemption and put in the scripts repository, to plot the gantt chart.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-02 ter 15:24]
- But, I did not update the qarnotNodeSchedAndrei. I'm still waiting for the StorageController.
:END:      
*** TODO To solve the problems with the packages in the Jupyter Notebook
 python3 -m ipykernel install --user
** wednesday, 03-04-2019
*** DONE To check the jupyter notebook with Pierre.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-05 sex 10:47]
I need to describe the experiments.
:END:      
*** DONE To do the simulation runs on Jupyter Notebook.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-05 sex 10:46]
We decided that we dont have more time to do it. And we will not run the full simulation during the presentation.
I will finish the Jupyter Notebook file about the analyzes to keep it available for any doubts.
:END:      
*** Meeting
**** Mission in Paris
***** To prepare the agenda
***** To prepare the presentation
***** Objectives
****** To show that the platform are full implemented
****** To show the edge computing things
****** ..?
***** TODO Presentation
****** Workflow diagram
******* Simulation of real platform AND our improvements
******* Real components
****** Analyzes
******* Temperature
******* Job Allocation
** REPORT Resubmission was done.                                :WeekReview:
** REPORT About the the resubmission, I created a new method on batsim.py. :WeekReview:
** REPORT Jupyter Notebook for whole analyzes (job allocation and temperature). :WeekReview:
** REPORT I though about analyze the energy consumption.         :WeekReview:
* Week 04-04 / 10-04
** thuersday, 04-04-2019
*** Journée des doctorants
*** I have been started to write the description of analyzes.
** friday, 05-04-2019
*** DONE To decide the experiments metrics
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-05 sex 17:04]
:END:      
**** TODO To write de full descriptions.
*** DONE To define the final version of the diagram
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-05 sex 17:04]
:END:      
**** TODO To draw the slides, step by step
*** Experiment design board                                          :ATTACH:
:PROPERTIES:
:Attachments: experiments.jpg
:ID:       d57b0d1c-3e5e-4e23-8298-7d787a065b0c
:END:

#+NAME: fig: experiments_board
#+ATTR_ORG: :width 500
file:data/d5/7b0d1c-3e5e-4e23-8298-7d787a065b0c/experiments.jpg
**** From the csv, outputs:
***** a. consumed_energy
***** b. jobs
***** c. machine_states
***** d. ps_change
***** e. schedule
***** f. temperature
***** TODO g. new_status [nb_preempted, cpu_burn, data_staging, nb_killed_at_end]
**** Metrics :
***** 1. from f. : get the temperature over time -> To validate that the standard version is correct and close to the real data.
***** 2. from b. : plot the gantt chart
***** 3. from g. : Compare if there are more or less preempted jobs, data_staging.
***** 4. from e. : Compare if the max_values, as waiting_time, are bigger or smaller. 
***** 5. from e. : Compare if the data_transfer_time is bigger or smaller. 
***** 6. from e. : Compare the consumed_joules, time_computing, time_scheduling. Is the diff. smaller or bigger?
**** Overview:
***** TODO 1,2,4,6. The csv are ready, just script it.
***** WAITING 2. Discuss with the team if is usefull to extract the real job allocation data.
***** WAITING 5, 7. We need to implement it.

** monday, 08-04-2019
*** WAITING Draw the slides for the diagrams
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-04-10 qua 10:10] \\
  Waiting review.
:END:      
*** TODO To finish to wite the experiment descriptions
**** TODO To check how and who will implement the modification to get the .csv as 5. and 7.
*** TODO To run the experiment with both schedulers
 | Workload    | NodeSched | NodeSchedAndrei | Diff | Plots       |
 | simple      |           |                 |      |             |
 | simple_more | DONE      | DONE            | TRUE | VISIBLE     |
 | 1_day       | DONE      | DONE            | TRUE | NOT VISIBLE |
 | 1_week      | DONE      | DONE            | TRUE | VSISBLE     |
 | 2_weeks     |           |                 |      |             |
 |             |           |                 |      |             |

**** I worked on the updates between the branches. I got the last version of the temperature branch and updated my version of the scheduler.
**** I need to check the data movements, because the scheduling is not changing.
** tuesday, 09-04-2019
*** DONE To check the data movements, aka., the job allocation of my scheduler.
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-11 qui 09:56]
:END:      
**** Looking as working :D. See example: triplet1 and 2 at subtime:300
*** DONE To change the print of names in the GanttChart with Evalys
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-11 qui 18:32]
- If the name_id is deleted, so the ganttChart is plotted without names. Its not the perfect solution. I should check how to do it properly.
:END:      
In the documentation:  labeler – The strategy to label jobs. By default, the jobID column is used to label jobs. To disable the labeling of jobs, simply return an empty string.
So, I deleted all values from the ID Column.
*** TODO To take a look in the Batsim demo [https://gitlab.inria.fr/batsim/batsim/blob/master/demo/BatsimDemo.ipynb], to plot some similar graphs.
Good link [http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/81-ggplot2-easy-way-to-mix-multiple-graphs-on-the-same-page/]
Gantt Chart with R [https://adrien-faure.fr/post/ganttcharts/]
*** I did the presentation for the diagram.
** wednesday, 10-04-2019
*** DONE To colletct other weeks
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-11 qui 18:33]
:END:      
*** Progress
| Task              | Status         | What is missing? |
| Plot GanttChart   |                |                  |
| Plot Temperature  |                |                  |
| Plot Many metrics |                |                  |
| Plot 4            |                |                  |
| Plot 5            |                |                  |
| Plot 6            |                |                  |
| Plot 7            |                |                  |
| Text Description  | ALMOST         |                  |
| Full experiments  | ALMOST         |                  |
| Workflow diagram  | DONE           |                  |
|                   |                |                  |

** thuesday, 11-04-2019
*** DONE rbind the _schedule.csv to get the columns as keys and the values as values. Also add a column origin = {standard, andrei}
:LOGBOOK:  
- State "DONE"       from "TODO"       [2019-04-11 qui 10:42]
:END:      
*** WAITING To save as csv the new outputs of pybatsim.
:LOGBOOK:  
- State "WAITING"    from "TODO"       [2019-04-11 qui 20:43] \\
  Coded to be saved as _schedule_plus.csv in the current directory of pybatsim. Check the correct place.
:END:      
*** TODO Count the number of new downloads done by the scheduler.
*** We had a meeting with Alex to discuss wat we will present in the Qarnot meeting.
